{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebe0fbd",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "\n",
    "## Robots.txt WARC records of top-10k domains\n",
    "\n",
    "Objective: extract the robots.txt WARC records of 10,000 top-ranking domains from [Common Crawl's robots.txt dataset](https://commoncrawl.org/2016/09/robotstxt-and-404-redirect-data-sets/).\n",
    "\n",
    "Note: the general procedure how to extract a records for a large list of domains is described in this [notebook](https://github.com/commoncrawl/cc-notebooks/blob/main/cc-index-table/bulk-url-lookups-by-table-joins.ipynb#Variants-and-Further-Optimizations) in more detail.\n",
    "\n",
    "- download the domain-level ranks ([cc-main-2022-may-jun-aug-domain-ranks.txt.gz](https://data.commoncrawl.org/projects/hyperlinkgraph/cc-main-2022-may-jun-aug/domain/cc-main-2022-may-jun-aug-domain-ranks.txt.gz)) from [May/Jun/Aug 2022 web graphs](https://commoncrawl.org/2022/09/host-and-domain-level-web-graphs-may-jun-aug-2022/) dataset\n",
    "- extract the top-10k domains as pair ⟨rank,domain⟩\n",
    "  ```bash\n",
    "  zcat data/cc-main-2022-may-jun-aug-domain-ranks.txt.gz \\\n",
    "      | tail -n+2 \\\n",
    "      | head -10000 \\\n",
    "      | cut -f1,5 \\\n",
    "      >data/cc-main-2022-may-jun-aug-domain-ranks-top-10k.txt\n",
    "  ```\n",
    "- convert the domain list to [Parquet](https://parquet.apache.org/) file format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c92cfd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>rev-domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>com.googleapis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>com.facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>com.google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>com.twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>com.youtube</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank      rev-domain\n",
       "0     1  com.googleapis\n",
       "1     2    com.facebook\n",
       "2     3      com.google\n",
       "3     4     com.twitter\n",
       "4     5     com.youtube"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/cc-main-2022-may-jun-aug-domain-ranks-top-10k.txt', sep='\\t', names=['rank', 'rev-domain'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616ceb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>googleapis.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>twitter.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>youtube.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank          domain\n",
       "0     1  googleapis.com\n",
       "1     2    facebook.com\n",
       "2     3      google.com\n",
       "3     4     twitter.com\n",
       "4     5     youtube.com"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unreverse the domain name\n",
    "\n",
    "def reverse_domain(d):\n",
    "    parts = d.split('.')\n",
    "    parts.reverse()\n",
    "    return '.'.join(parts)\n",
    "\n",
    "df['domain'] = df['rev-domain'].apply(reverse_domain)\n",
    "del(df['rev-domain'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "635ca3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as Parquet\n",
    "df.to_parquet('data/cc-main-2022-may-jun-aug-domain-ranks-top-10k.parquet.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401c20b",
   "metadata": {},
   "source": [
    "### Bulk lookup by table join\n",
    "\n",
    "The lookup of all 10k domains in the [columnar index](https://commoncrawl.org/2018/03/index-to-warc-files-and-urls-in-columnar-format/) requires to\n",
    "\n",
    "- upload the Parquet domain list to S3 (`mybucket` is a placeholder for a bucket in `us-east-1`)\n",
    "  ```bash\n",
    "  aws s3 cp data/cc-main-2022-may-jun-aug-domain-ranks-top-10k.parquet.gz s3://mybucket/robotstxt-experiments/domain-top-10k/\n",
    "  ```\n",
    "- register the domain list as table in [Amazon Athena](https://aws.amazon.com/athena/)\n",
    "  - navigate to the [Athena query editor](https://console.aws.amazon.com/athena/home?region=us-east-1#/query-editor) and\n",
    "  - create a database \"robotsexperiments\" by executing the following statement:\n",
    "    ```sql\n",
    "    CREATE DATABASE robotsexperiments;\n",
    "    ```\n",
    "  - register the table \"topdomains\":\n",
    "    ```sql\n",
    "    CREATE EXTERNAL TABLE IF NOT EXISTS robotsexperiments.topdomains (\n",
    "      `rank`  int,\n",
    "      `domain` string\n",
    "    )\n",
    "    ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
    "    WITH SERDEPROPERTIES (\n",
    "      'serialization.format' = '1'\n",
    "    ) LOCATION 's3://mybucket/robotstxt-experiments/domain-top-10k/'\n",
    "    TBLPROPERTIES ('has_encrypted_data'='false');\n",
    "    ```\n",
    "  - and verify whether the table is imported properly and contains the expected number of rows\n",
    "    ```sql\n",
    "    SELECT * FROM robotsexperiments.topdomains limit 10;\n",
    "  \n",
    "    SELECT COUNT(*) FROM robotsexperiments.topdomains;\n",
    "    ```\n",
    "\n",
    "Finally, the bulk lookup is done by a table join with the [Common Crawl's columnar index](ttps://commoncrawl.org/2018/03/index-to-warc-files-and-urls-in-columnar-format/), we\n",
    "- select only the most recent record per same robots.txt URL (the crawler might fetch the robots.txt repeatedly during a monthly crawling running over almost two weeks)\n",
    "- extract WARC record locations for later processing of robots.txt records\n",
    "- MIME types (HTTP Content-Type header and identified by content)\n",
    "- fetch time and status\n",
    "- and redirect locations (since CC-MAIN-2019-47) in order to \"follow\" redirects\n",
    "\n",
    "```sql\n",
    "WITH allrobots AS (\n",
    "  SELECT alexa.site,\n",
    "         alexa.rank,\n",
    "         cc.url_host_tld,\n",
    "         cc.url_host_registered_domain,\n",
    "         cc.url_host_name,\n",
    "         cc.url,\n",
    "         cc.fetch_time,\n",
    "         cc.fetch_status,\n",
    "         cc.warc_filename,\n",
    "         cc.warc_record_offset,\n",
    "         cc.warc_record_length,\n",
    "         cc.fetch_redirect,\n",
    "         cc.content_mime_type,\n",
    "         cc.content_mime_detected,\n",
    "         -- enumerate records of same URL, most recent first\n",
    "         ROW_NUMBER() OVER(PARTITION BY cc.url ORDER BY cc.fetch_time DESC) AS n\n",
    "  FROM \"ccindex\".\"ccindex\" AS cc\n",
    "    RIGHT OUTER JOIN \"ccindex\".\"alexa_top_1m\" AS alexa\n",
    "    ON alexa.domain = cc.url_host_registered_domain\n",
    "  WHERE cc.crawl = 'CC-MAIN-2022-33'\n",
    "    AND cc.subset = 'robotstxt'\n",
    "    -- skip host names which differ from the domain name except for an optional \"www.\" prefix\n",
    "    AND (length(cc.url_host_name) = length(cc.url_host_registered_domain)\n",
    "         OR (length(cc.url_host_name) = (length(cc.url_host_registered_domain)+4)\n",
    "             AND substr(cc.url_host_name, 1, 4) = 'www.')))\n",
    "SELECT *\n",
    " FROM allrobots\n",
    "-- select only the first (most recent) record of the same URL\n",
    "WHERE allrobots.n = 1;\n",
    "```\n",
    "\n",
    "The query extracts the robots.txt records for a single monthly crawl (CC-MAIN-2022-33). We repeat it for crawls in other years, run in August or September: CC-MAIN-2021-39, CC-MAIN-2020-34, CC-MAIN-2019-35, C-MAIN-2018-34, CC-MAIN-2017-34, C-MAIN-2016-36. Results are stored as `data/cc-main-2022-33-robotstxt-captures.csv` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e0ac4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    164783\n",
       "2019    137307\n",
       "2018    123319\n",
       "2021     99524\n",
       "2017     78991\n",
       "2022     72685\n",
       "2016     21633\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read all result files into a dataframe\n",
    "\n",
    "import glob\n",
    "\n",
    "robots_captures = glob.glob('data/cc-main-*-robotstxt-captures.csv')\n",
    "\n",
    "robots_captures_df = []\n",
    "for f in robots_captures:\n",
    "    d = pd.read_csv(f, index_col=None)\n",
    "    d['crawl'] = f[5:20]\n",
    "    d['year'] = f[13:17]\n",
    "    robots_captures_df.append(d)\n",
    "\n",
    "df = pd.concat(robots_captures_df, axis=0, ignore_index=True)\n",
    "\n",
    "df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb0f925f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content_mime_detected   \n",
       "text/html                   420944\n",
       "text/plain                  125032\n",
       "application/xhtml+xml        47877\n",
       "application/octet-stream     32970\n",
       "application/x-msdownload     31096\n",
       "                             ...  \n",
       "text/plan                        1\n",
       "application/zip                  1\n",
       "audio/vnd.wave                   1\n",
       "plain/text                       1\n",
       "video/x-sgi-movie                1\n",
       "Length: 76, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['content_mime_detected']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9ffaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only \"real\" robots.txt files (fetch status = HTTP 200, plain text, not HTML)\n",
    "\n",
    "def is_robotstxt(r: pd.Series):\n",
    "    if r['fetch_status'] != 200:\n",
    "        return False\n",
    "    # plain text MIME types including some noise due to erroneous detections and spell errors\n",
    "    plain_text_mime_types = {'text/x-robots', 'text/plain', 'message/rfc822', 'text/text', 'text/txt',\n",
    "                             'text', 'plain/text', 'text/pain', 'text/plan'}\n",
    "    if (r['content_mime_detected']\n",
    "        and r['content_mime_detected'] in plain_text_mime_types):\n",
    "        # since 2018 MIME types are detected based on content\n",
    "        return True\n",
    "    if (r['content_mime_type'] in plain_text_mime_types):\n",
    "        # otherwise we have to rely the HTTP Content-Type header\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "df['is_robotstxt'] = df.apply(is_robotstxt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5542c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>is_robotstxt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016</th>\n",
       "      <th>False</th>\n",
       "      <td>7497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>14136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2017</th>\n",
       "      <th>False</th>\n",
       "      <td>66156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>12835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2018</th>\n",
       "      <th>False</th>\n",
       "      <td>110929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>12390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2019</th>\n",
       "      <th>False</th>\n",
       "      <td>125169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>12138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2020</th>\n",
       "      <th>False</th>\n",
       "      <td>152383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2021</th>\n",
       "      <th>False</th>\n",
       "      <td>87381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>12143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2022</th>\n",
       "      <th>False</th>\n",
       "      <td>60539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>12146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "year is_robotstxt        \n",
       "2016 False           7497\n",
       "     True           14136\n",
       "2017 False          66156\n",
       "     True           12835\n",
       "2018 False         110929\n",
       "     True           12390\n",
       "2019 False         125169\n",
       "     True           12138\n",
       "2020 False         152383\n",
       "     True           12400\n",
       "2021 False          87381\n",
       "     True           12143\n",
       "2022 False          60539\n",
       "     True           12146"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# over the years we get an almost stable number of \"real\" robots.txt files\n",
    "\n",
    "df[['year', 'is_robotstxt']].value_counts().to_frame().sort_values(['year', 'is_robotstxt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab535fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract \"real\" robots.txt records and keep only one record per domain\n",
    "\n",
    "real_robots_captures = df[df['is_robotstxt']].sort_values(['fetch_time']) \\\n",
    "    .drop_duplicates(['year', 'url_host_registered_domain'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46f2f49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>7223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>7161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>7522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>7598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>7661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>7678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>7588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year\n",
       "2016  7223\n",
       "2017  7161\n",
       "2018  7522\n",
       "2019  7598\n",
       "2020  7661\n",
       "2021  7678\n",
       "2022  7588"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_robots_captures['year'].value_counts().to_frame().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499db600",
   "metadata": {},
   "source": [
    "This looks close to a balanced sample:\n",
    "- we do not have robots.txt files for all 10,000 domains (about 25% missing)\n",
    "- more files missing for prior years (but that's expected because the domain list is from 2022)\n",
    "\n",
    "Now, let's dump the lists for fetching the robots.txt captures..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e6fcb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for crawl, d in real_robots_captures.groupby('crawl'):\n",
    "   d.to_csv('data/{}-robotstxt-captures-selected.csv'.format(crawl), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ac8219",
   "metadata": {},
   "source": [
    "### Fetching robots.txt captures\n",
    "\n",
    "(see [cc-index-table](https://github.com/commoncrawl/cc-index-table#export-subsets-of-the-common-crawl-archives))\n",
    "\n",
    "\n",
    "### Parsing robots.txt captures\n",
    "\n",
    "[robotstxt_statistics.py](./robotstxt_statistics.py) based on [cc-pyspark](https://github.com/commoncrawl/cc-pyspark)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
